# Using the Real Agent-Powered Gradio App

## New File: `app_with_agents.py`

We've created a new version of the Gradio app that uses **real LLM agents** instead of mocks!

## Key Features

### 1. Real AI Agent Integration ‚úÖ

The app now calls actual OpenAI and Anthropic APIs:
- 6 specialized sub-agents run in parallel
- Real JSON generation
- Composer Agent synthesizes outputs
- Choose between OpenAI (GPT-4o mini) or Anthropic (Claude Haiku 4.5)

### 2. Response Caching üí∞

**Problem:** Every time you iterate on the GameDef, you'd have to re-call all 6 sub-agents ($$$)

**Solution:** The app caches sub-agent results!

**How it works:**
1. Generate a game ‚Üí All 6 sub-agent responses are cached
2. Click "Regenerate GameDef" ‚Üí Uses cached results, only calls Composer
3. **Savings:** ~85% cost reduction when iterating!

**Example:**
- First generation: $0.0085 (6 sub-agents + composer)
- Regeneration: ~$0.0013 (composer only)
- **5x cost savings** when iterating!

### 3. Provider Selection ü§ñ

Choose which API to use for sub-agents:
- **OpenAI (GPT-4o mini)** - Faster, cheaper ($0.15/1M tokens)
- **Anthropic (Claude Haiku 4.5)** - Higher quality ($1/1M tokens)

Composer always uses Claude Sonnet 4.5 for best synthesis quality.

## How to Run

### 1. Make sure API keys are set in `.env.local`:
```bash
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
```

### 2. Stop the old app (if running):
```bash
# Find the process
lsof -i :7860
# Kill it
kill <PID>
```

### 3. Run the new app:
```bash
source venv/bin/activate
python app_with_agents.py
```

### 4. Open browser:
```
http://localhost:7860
```

## Usage Flow

### Generate a New Game

1. **Select mode** (Relaxing, Funny, Chaotic, Challenge, Surprise Me)
2. **Choose provider** (openai or anthropic)
3. **Fill in Mad-Lib fields**
4. **Click "Generate My Game!"**
5. Watch as:
   - Sub-agents launch in parallel
   - Real LLM calls are made
   - Composer synthesizes the results
   - GameDef JSON is generated

### Iterate on the GameDef

After generating once:

1. **Click "Regenerate GameDef (Use Cached Results)"**
2. The Composer runs again with the cached sub-agent outputs
3. Get a new GameDef variation **without re-calling sub-agents**
4. **Save API costs!**

## What You'll See

### Generation Status

```
üéÆ Our Mad-Lib Factory Generates Games

üöÄ Starting game generation...

‚ö° Launching sub-agents in parallel:
  ‚Ä¢ ü§ñ Launching Character Agent
  ‚Ä¢ ü§ñ Launching Mechanic Agent
  ‚Ä¢ ü§ñ Launching Style Agent
  ‚Ä¢ ü§ñ Launching Conflict Agent
  ‚Ä¢ ü§ñ Launching Level Agent
  ‚Ä¢ ü§ñ Launching Twist Agent

Using OPENAI API

‚è≥ Running agents in parallel...
  ‚úì Character Agent complete
  ‚úì Mechanic Agent complete
  ‚úì Style Agent complete
  ‚úì Conflict Agent complete
  ‚úì Level Agent complete
  ‚úì Twist Agent complete

‚úÖ All sub-agents complete!

üéº Launching Composer Agent
  ‚Ä¢ Collecting sub-agent outputs...
  ‚Ä¢ Validating coherence...
  ‚Ä¢ Constructing GameDef JSON...
  ‚Ä¢ Generated shareable slug: funny-4273

‚úÖ Game generation complete!
```

### Game Output

You'll see:
- Complete GameDef JSON
- User inputs used
- Shareable slug
- Note about cached results

## Cost Comparison

### Without Caching (Old Way)
Every iteration requires full agent calls:
- Iteration 1: $0.0085
- Iteration 2: $0.0085
- Iteration 3: $0.0085
- **Total:** $0.0255

### With Caching (New Way)
Only first call hits all agents:
- Iteration 1: $0.0085
- Iteration 2: $0.0013 (composer only)
- Iteration 3: $0.0013 (composer only)
- **Total:** $0.0111
- **Savings:** 56% cheaper!

## Technical Details

### Caching Implementation

Uses Gradio State to store sub-agent results:

```python
cached_state = gr.State(value=None)

# On generate
yield status, game_output, sub_agent_outputs  # Updates cache

# On regenerate
regenerate_gamedef(mode, cached_results)  # Uses cache
```

### Async Execution

Sub-agents run in parallel using `asyncio.gather()`:

```python
results = await asyncio.gather(
    character_agent.generate(...),
    mechanic_agent.generate(...),
    style_agent.generate(...),
    # ... etc
)
```

## Troubleshooting

### API Key Errors
```
‚ùå Error: No API key found
```

**Fix:** Make sure `.env.local` has your keys:
```bash
cat .env.local
```

### Module Not Found
```
ModuleNotFoundError: No module named 'agents'
```

**Fix:** Make sure you're running from the project directory:
```bash
cd /Users/jrogers/code/github/omfgg
source venv/bin/activate
python app_with_agents.py
```

### No Cached Results
```
‚ö†Ô∏è No cached results available
```

**Fix:** Generate a game first before using "Regenerate"

## Comparison: Mock vs Real

| Feature | app.py (Mock) | app_with_agents.py (Real) |
|---------|---------------|---------------------------|
| Sub-agents | Simulated delays | Real LLM API calls |
| Output | Static mock text | Dynamic JSON generation |
| Cost | Free | ~$0.0085/game |
| Caching | No | Yes ‚úÖ |
| Provider choice | No | Yes (OpenAI/Anthropic) |
| Quality | Fixed | Varies with creativity |
| Speed | ~5 seconds | ~8-15 seconds |

## Next Steps

Now that we have real agents working:

1. **Test all 5 modes** - Ensure quality across all game types
2. **Add MCP integration** - Store/retrieve games
3. **Build game renderer** - Actually play the games
4. **Deploy to HuggingFace** - Make it publicly accessible

## Files

- `app.py` - Original mock version (still works)
- `app_with_agents.py` - New real agent version ‚≠ê
- `agents.py` - Agent implementations
- `test_agents.py` - Quick API test
- `.env.local` - Your API keys (gitignored)

## Tips

- Use **OpenAI** for development (cheaper, faster)
- Use **Anthropic** for final demos (higher quality)
- **Regenerate** instead of re-generating to save costs
- Keep an eye on API usage in your dashboards
